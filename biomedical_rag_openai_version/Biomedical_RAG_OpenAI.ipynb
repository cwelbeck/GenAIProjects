{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical RAG QA using OpenAI LLM + FAISS\n",
    "This notebook implements a biomedical question answering system using a Retrieval-Augmented Generation (RAG) pipeline with OpenAI's GPT model and FAISS for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai faiss-cpu sentence-transformers gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'The hippocampus plays a key role in memory formation and spatial navigation.',\n",
    "    'Mutations in the CFTR gene cause cystic fibrosis, affecting the lungs and digestive system.',\n",
    "    'Insulin regulates glucose metabolism and is produced by the beta cells of the pancreas.',\n",
    "    'The BRCA1 and BRCA2 genes are involved in DNA repair and are linked to breast cancer.',\n",
    "    'Alzheimerâ€™s disease is associated with amyloid plaques and neurofibrillary tangles.'\n",
    "] * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "embedder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=False, show_progress_bar=True)\n",
    "index = faiss.IndexFlatL2(len(corpus_embeddings[0]))\n",
    "index.add(np.array(corpus_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def rag_qa_openai(query):\n",
    "    query_embedding = embedder.encode([query])[0]\n",
    "    D, I = index.search(np.array([query_embedding]), k=5)\n",
    "    retrieved_docs = [corpus[i] for i in I[0]]\n",
    "    context = "\n\n".join(retrieved_docs)\n",
    "    prompt = f"You are a biomedical expert. Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\nAnswer:"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{"role": "user", "content": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "demo = gr.Interface(\n",
    "    fn=rag_qa_openai,\n",
    "    inputs=gr.Textbox(label='Ask a biomedical question'),\n",
    "    outputs=gr.Textbox(label='Answer'),\n",
    "    title='Biomedical RAG QA (OpenAI)',\n",
    "    description='Ask biomedical questions with retrieval-based answers using OpenAI LLM.'\n",
    ")\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
