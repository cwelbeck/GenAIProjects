{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010ccc95",
   "metadata": {},
   "source": [
    "# ðŸš— Project: Autonomous Driving Perception Module\n",
    "This notebook demonstrates how to implement a multi-task perception system using segmentation and object detection for autonomous driving using the BDD100K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63759370",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models.segmentation as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image (replace with your own or use BDD100K sample)\n",
    "img_path = 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Street_in_New_York_City.JPG/640px-Street_in_New_York_City.JPG'\n",
    "import requests\n",
    "from io import BytesIO\n",
    "image = Image.open(BytesIO(requests.get(img_path).content)).convert('RGB')\n",
    "image = image.resize((640, 360))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac966a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.deeplabv3_resnet50(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_tensor)['out'][0]\n",
    "segmentation = output.argmax(0).byte().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(segmentation)\n",
    "plt.title('Semantic Segmentation Output')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a7507",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "This notebook uses PyTorchâ€™s DeepLabV3 for semantic segmentation on a road scene image. You can extend this project to:\n",
    "- Train on the [BDD100K](https://bdd-data.berkeley.edu/) dataset.\n",
    "- Combine with object detection (YOLO, Faster R-CNN).\n",
    "- Add lane detection or drivable area classification.\n",
    "- Deploy using TorchScript or TensorRT for real-time inference."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
