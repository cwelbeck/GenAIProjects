{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4051c94c",
   "metadata": {},
   "source": [
    "# ðŸ§  Project: Vision Transformer (ViT) Classifier for Medical or Satellite Imagery\n",
    "This notebook walks through fine-tuning a pre-trained Vision Transformer (ViT) on a medical or satellite image classification task using Hugging Face Transformers and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd322d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torchvision timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EuroSAT (satellite imagery) dataset\n",
    "dataset = load_dataset('eurosat', split='train[:1000]')\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example):\n",
    "    image = example['image'].convert('RGB')\n",
    "    example['pixel_values'] = feature_extractor(images=image, return_tensors='pt')['pixel_values'][0]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['pixel_values', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224',\n",
    "    num_labels=dataset['train'].features['label'].num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./vit-results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d037abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e702f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5743d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce601bb",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "This notebook demonstrates how to fine-tune a Vision Transformer on satellite imagery using the EuroSAT dataset. You can swap the dataset for medical images or fine-tune on your own labeled data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
