{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical Question Answering with RAG (Open Source + Google Colab Compatible)\n",
    "This notebook builds a Biomedical RAG (Retrieval-Augmented Generation) system using open-source LLMs and the BioASQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers datasets faiss-cpu sentence-transformers gradio accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BioASQ dataset as biomedical corpus\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('bioasq_task_b', split='train[:1000]')\n",
    "corpus = [item['body'] for item in dataset if item.get('body')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings using sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=False, show_progress_bar=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(len(corpus_embeddings[0]))\n",
    "index.add(np.array(corpus_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BioBART open-source model\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "model_name = 'bionlp/biobart-v2.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "qa_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG QA function\n",
    "def rag_qa(query):\n",
    "    query_embedding = embedder.encode([query])[0]\n",
    "    D, I = index.search(np.array([query_embedding]), k=5)\n",
    "    retrieved_docs = [corpus[i] for i in I[0]]\n",
    "    context = ' '.join(retrieved_docs)\n",
    "    prompt = f'question: {query} context: {context}'\n",
    "    result = qa_pipeline(prompt, max_length=256)[0]['generated_text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=rag_qa,\n",
    "    inputs=gr.Textbox(label='Ask a biomedical question'),\n",
    "    outputs=gr.Textbox(label='AI-generated answer'),\n",
    "    title='Biomedical RAG QA (BioASQ Dataset)',\n",
    "    description='RAG pipeline using open-source biomedical embeddings + BioBART for QA'\n",
    ")\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
