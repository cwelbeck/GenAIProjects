{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community faiss-cpu gradio pypdf pandas beautifulsoup4 huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ca259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, CSVLoader, TextLoader, WebBaseLoader\n",
    "\n",
    "def load_pdf(path): return PyPDFLoader(path).load()\n",
    "def load_csv(path): return CSVLoader(file_path=path).load()\n",
    "def load_text(path): return TextLoader(path).load()\n",
    "def load_url(url): return WebBaseLoader(url).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9244254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=500, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7425eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "docs = load_text(\"sample.txt\")  # Replace with your actual file\n",
    "chunks = split_documents(docs)\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.2, \"max_length\": 256})\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "def ask_question(query):\n",
    "    return qa_chain.run(query)\n",
    "\n",
    "iface = gr.Interface(fn=ask_question, inputs=\"text\", outputs=\"text\", title=\"LangChain RAG Chatbot\")\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}