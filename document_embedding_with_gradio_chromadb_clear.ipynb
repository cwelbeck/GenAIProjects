{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 Semantic Document Search with ChromaDB (Local + Cloud-ready)\n", "Supports TXT, PDF, DOCX, CSV, JSON, and Website URLs with persistent vector store using ChromaDB."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce6 Install Dependencies\n", "Ensure all required Python packages are installed including `chromadb`, `sentence-transformers`, `pdfplumber`, and `gradio`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install transformers sentence-transformers torch chromadb gradio pdfplumber python-docx pandas beautifulsoup4 requests"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Load Embedding Model\n", "We use `sentence-transformers/all-MiniLM-L6-v2`, a lightweight transformer-based model ideal for semantic search tasks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import gradio as gr\n", "import pdfplumber, docx, pandas as pd, json as js, requests\n", "from bs4 import BeautifulSoup\n", "from sentence_transformers import SentenceTransformer\n", "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcc2 Extract Text from Files and Websites\n", "This utility supports common document formats and extracts raw text for embedding. Also includes support for website URLs using BeautifulSoup."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Extract text from various formats and websites\n", "def extract_text(file):\n", "    name = file.name.lower()\n", "    if name.endswith(\".pdf\"):\n", "        with pdfplumber.open(file.name) as pdf:\n", "            return \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages)\n", "    elif name.endswith(\".docx\"):\n", "        doc = docx.Document(file.name)\n", "        return \"\\n\".join([para.text for para in doc.paragraphs])\n", "    elif name.endswith(\".csv\"):\n", "        df = pd.read_csv(file.name)\n", "        return df.to_string(index=False)\n", "    elif name.endswith(\".json\"):\n", "        data = js.load(file)\n", "        return js.dumps(data, indent=2)\n", "    else:\n", "        return file.read().decode(\"utf-8\", errors=\"ignore\")\n", "\n", "def extract_website_text(url):\n", "    try:\n", "        response = requests.get(url)\n", "        soup = BeautifulSoup(response.content, 'html.parser')\n", "        return soup.get_text()\n", "    except Exception as e:\n", "        return f\"Error fetching website: {str(e)}\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddf1 Text Chunking\n", "To improve retrieval quality, long documents are broken into overlapping chunks using a sliding window technique."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Text chunking utility\n", "def chunk_text(text, chunk_size=300, overlap=50):\n", "    words = text.split()\n", "    chunks = []\n", "    for i in range(0, len(words), chunk_size - overlap):\n", "        chunk = ' '.join(words[i:i + chunk_size])\n", "        chunks.append(chunk)\n", "    return chunks"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcbe ChromaDB Setup\n", "Chroma is initialized in local mode by default. You may optionally use the commented `HttpClient` code to connect to a cloud-hosted instance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ChromaDB Setup (Local SQLite, with optional cloud client commented)\n", "import chromadb\n", "from chromadb.utils import embedding_functions\n", "# from chromadb.config import Settings\n", "# chroma_client = chromadb.HttpClient(host='your-host', port=your-port, headers={\"Authorization\": \"Bearer YOUR_API_KEY\"})\n", "chroma_client = chromadb.Client()  # Local persistence\n", "collection = chroma_client.get_or_create_collection(name=\"document_chunks\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce4 Upload Files and Store in ChromaDB\n", "Text chunks are embedded and stored in the Chroma collection, along with unique IDs and metadata."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Upload and embed using ChromaDB\n", "import uuid\n", "\n", "def process_files_chroma(file_objs):\n", "    global doc_texts\n", "    doc_texts = []\n", "    ids = []\n", "    metadatas = []\n", "    for file in file_objs:\n", "        raw_text = extract_text(file)\n", "        chunks = chunk_text(raw_text)\n", "        doc_texts.extend(chunks)\n", "        for chunk in chunks:\n", "            ids.append(str(uuid.uuid4()))\n", "            metadatas.append({\"source\": file.name})\n", "    embeddings = model.encode(doc_texts).tolist()\n", "    collection.add(documents=doc_texts, embeddings=embeddings, metadatas=metadatas, ids=ids)\n", "    return f\"\u2705 Uploaded {len(doc_texts)} chunks to ChromaDB.\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d Semantic Search from ChromaDB\n", "The query is encoded and compared to stored vectors in Chroma. The most relevant document is returned."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Search ChromaDB\n", "def search_document_chroma(query):\n", "    embedding = model.encode([query]).tolist()\n", "    results = collection.query(query_embeddings=embedding, n_results=1)\n", "    return results['documents'][0][0] if results['documents'] else 'No match found.'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Gradio UI with ChromaDB support\n", "with gr.Blocks() as demo:\n", "    gr.Markdown(\"# \ud83e\udde0 ChromaDB-Powered Document Search\")\n", "\n", "    with gr.Row():\n", "        file_input = gr.File(file_types=['.txt', '.pdf', '.docx', '.csv', '.json'], file_count=\"multiple\", label=\"\ud83d\udcc4 Upload Files\")\n", "        upload_output = gr.Textbox(label=\"Upload Result\")\n", "\n", "    with gr.Row():\n", "        query_input = gr.Textbox(label=\"\ud83d\udd0d Enter your search query\")\n", "        search_output = gr.Textbox(label=\"Best Matching Document\")\n", "\n", "    upload_button = gr.Button(\"Upload to Chroma\")\n", "    upload_button.click(process_files_chroma, inputs=file_input, outputs=upload_output)\n", "\n", "    search_button = gr.Button(\"Search in Chroma\")\n", "    search_button.click(search_document_chroma, inputs=query_input, outputs=search_output)\n", "\n", "demo.launch()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Clear uploaded documents and reset the collection (in-memory only)\n", "def clear_uploaded():\n", "    global doc_texts\n", "    doc_texts.clear()\n", "    chroma_client.delete_collection(name=\"document_chunks\")\n", "    return \"\ud83d\uddd1\ufe0f Cleared all uploaded documents and embeddings.\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["    clear_button.click(clear_uploaded, outputs=upload_output)", "    clear_button = gr.Button(\"\ud83d\uddd1\ufe0f Clear Uploads\")", "## \ud83d\udda5\ufe0f Interactive Gradio UI\n", "This user interface allows you to upload documents, embed them to Chroma, and search semantically with ease."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}